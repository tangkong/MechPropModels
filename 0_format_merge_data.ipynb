{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from matminer.featurizers.base import MultipleFeaturizer, StackedFeaturizer\n",
    "from matminer.featurizers import composition as cf\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV, ShuffleSplit, LeaveOneGroupOut, cross_val_score, learning_curve, KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import Imputer, LabelEncoder\n",
    "from sklearn.metrics import roc_curve, auc, r2_score, make_scorer\n",
    "from sklearn import metrics\n",
    "from pymatgen import Composition\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gzip\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featCleanImpute(Y):\n",
    "    ''' Convert inf to NaN in feature array, in place\n",
    "    \n",
    "    Args: \n",
    "        Y, feature array, list of ndarray (#samples x #features)\n",
    "    Returns:\n",
    "        None\n",
    "    '''\n",
    "    # Clean inf values\n",
    "    for i in range(len(Y)):\n",
    "        for j in range(len(Y[i])):\n",
    "            if Y[i][j] == np.inf:\n",
    "                Y[i][j] = np.nan\n",
    "            else:\n",
    "                Y[i][j] = Y[i][j]\n",
    "                \n",
    "    # Impute nan values\n",
    "    imp = Imputer(missing_values='NaN', axis=0, strategy='mean', copy=False)\n",
    "    imp2 = Imputer(missing_values='NaN', axis=1, strategy='mean', copy=False)\n",
    "\n",
    "    imp.fit(Y)\n",
    "    imp.transform(Y)\n",
    "    imp2.fit(Y)\n",
    "    imp.transform(Y)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and Format datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elastProp_SLAC = pd.read_excel('datasets/Mechnical properties analysis v33_Pruned.xlsx')\n",
    "rawCopy = elastProp_SLAC.copy()\n",
    "len(rawCopy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "elastProp_SLAC.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elastProp_SLAC.rename(index=str, columns={'θd':'theta_d', 'ρ (g/cm3)':'density (g/cm3)', \n",
    "                                          'Yeild strength, σy (MPa)':'Yeild strength (MPa)', \n",
    "                                         'Compressive fracture strength, σf (MPa)': 'Compressive fracture strength (MPa)'},inplace=True)\n",
    "#elastProp_SLAC.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfSLAC = elastProp_SLAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeComp(x):\n",
    "    '''Apply Composition() constructor to string x\n",
    "       Return: Composition object, or 0 if not parse-able'''\n",
    "    try:\n",
    "        return Composition(x)\n",
    "    except:\n",
    "        print(x)\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfSLAC['comp'] = dfSLAC['Compositions'].apply(makeComp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove entries where composition was unable to be read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfSLAC = dfSLAC[dfSLAC['comp']!=0]\n",
    "dfSLAC.reset_index(drop=True, inplace=True)\n",
    "print('{} entries remaining'.format(len(dfSLAC)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = dfSLAC.columns.tolist()\n",
    "dfSLAC = dfSLAC[cols[-1:] + cols[:-1]]\n",
    "print(\"moved 'comp' to first column\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dfSLAC['comp']!=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def redComp(x):\n",
    "    try: \n",
    "        return Composition(x.reduced_formula)\n",
    "    except: \n",
    "        print(x)\n",
    "        return 0\n",
    "    \n",
    "dfSLAC['comp'] = dfSLAC['comp'].apply(redComp)\n",
    "dfSLAC = dfSLAC[dfSLAC['comp']!=0]\n",
    "dfSLAC.reset_index(drop=True, inplace=True)\n",
    "print('{} entries remaining'.format(len(dfSLAC)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfSLAC['compStr'] = dfSLAC['comp'].apply(lambda x: x.reduced_formula)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfSLAC.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import NREL dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NRELmodulusDataPath= 'C:\\\\Users\\\\Hikaru\\\\Desktop\\\\School\\\\_Stanford\\\\_SLAC\\\\MechPropModels\\\\ryan\\'s code\\\\MG_elastic_properties_package\\\\datasets\\\\SLAC_Modulus_Only_Cleaned_modified_trim.xlsx'\n",
    "elastProp_NREL = pd.read_excel(NRELmodulusDataPath)\n",
    "rawCopy = elastProp_NREL.copy()\n",
    "rawCopy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elastProp_NREL['comp'] = elastProp_NREL['Compositions'].apply(makeComp)\n",
    "elastProp_NREL['comp'] = elastProp_NREL['comp'].apply(redComp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elastProp_NREL['comp'][0]\n",
    "# Compositions have been standardized and reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell about Composition.almost_equal() method experimentation was here\n",
    "# Note that an unreduced chemical formula is not equal in composition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build individual datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate, clean feature set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_featurizer = MultipleFeaturizer([cf.Stoichiometry(), cf.ElementProperty.from_preset(\"magpie\"),\n",
    "                                 cf.ValenceOrbital(props=['avg']), cf.IonProperty(fast=True),\n",
    "                                cf.YangSolidSolution(), cf.AtomicPackingEfficiency()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Young's Modulus dataset \n",
    "Isolate Youngs Modulus, Composition.\n",
    "Build Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate Data into new frame\n",
    "youngsSLAC = pd.DataFrame()\n",
    "youngsSLAC['comp'] = dfSLAC['comp']\n",
    "youngsSLAC['E'] = dfSLAC['Young’s  Modulus, E (GPa)']\n",
    "\n",
    "# Drop missing entries \n",
    "youngsSLAC = youngsSLAC[[(type(x) in (int, float)) for x in youngsSLAC['E']]]\n",
    "youngsSLAC.reset_index(drop=True, inplace=True)\n",
    "youngsSLAC = youngsSLAC[~youngsSLAC['E'].isnull()]\n",
    "youngsSLAC['E'].astype(float)\n",
    "youngsSLAC.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separate Data into new frame\n",
    "youngsNREL = pd.DataFrame()\n",
    "youngsNREL['comp'] = elastProp_NREL['comp']\n",
    "youngsNREL['E'] = elastProp_NREL['Youngs_Modulus_GPa']\n",
    "\n",
    "# Drop missing entries\n",
    "youngsNREL = youngsNREL[[(type(x) in (int, float)) for x in youngsNREL['E']]]\n",
    "youngsNREL.reset_index(drop=True, inplace=True)\n",
    "youngsNREL = youngsNREL[~youngsNREL['E'].isnull()]\n",
    "youngsNREL['E'].astype(float)\n",
    "youngsNREL.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join and sort data (SLAC dataset is complete)\n",
    "youngsData = youngsSLAC #.append(youngsNREL, ignore_index=True)\n",
    "youngsData = youngsData.sort_values('comp').reset_index(drop=True)\n",
    "print('{} = {} + {}?'.format(len(youngsData), len(youngsSLAC), len([])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X_E = base_featurizer.featurize_many(youngsData['comp'], ignore_errors=True)\n",
    "X_E = np.array(X_E)\n",
    "X_E.astype(float)\n",
    "print('Computed {} features'.format(X_E.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create smaller dataset for quick tests\n",
    "youngsDataSmall = youngsData.sample(500).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XEsmall = base_featurizer.featurize_many(youngsDataSmall['comp'], ignore_errors=True)\n",
    "XEsmall = np.array(XEsmall)\n",
    "XEsmall.astype(float)\n",
    "print('Computed {} features'.format(XEsmall.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some duplicates exist\n",
    "comp = Composition('Zr14Al4Co7')\n",
    "comp2 = Composition('Zr20Al4Co7') \n",
    "for index, row in youngsData[ [x.almost_equals(comp) for x in youngsData['comp']] ].iterrows():\n",
    "    print('Comp: {} .... at row: {}'.format(row['comp'], index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.where(np.isnan(X_E)))\n",
    "featCleanImpute(X_E)\n",
    "print(np.where(np.isnan(X_E)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('./datasets/youngs_features.pkl.gz', 'wb') as fp:\n",
    "    pkl.dump(X_E, fp)\n",
    "with gzip.open('./datasets/youngs_data.pkl.gz', 'wb') as fd:\n",
    "    pkl.dump(youngsData, fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('./datasets/youngsSmall_features.pkl.gz', 'wb') as fp:\n",
    "    pkl.dump(XEsmall, fp)\n",
    "with gzip.open('./datasets/youngsSmall_data.pkl.gz', 'wb') as fd:\n",
    "    pkl.dump(youngsDataSmall, fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "youngsDataReduced = pd.DataFrame()\n",
    "yDcopy = youngsData.copy()\n",
    "while ~yDcopy.empty:\n",
    "    compTemp = yDcopy['comp'][0]\n",
    "    dupes = yDcopy[ [x.almost_equals(comp) for x in yDcopy['comp']] ]\n",
    "    \n",
    "    \n",
    "    \n",
    "    break\n",
    "    yDcopy.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dupes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfSLAC.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Density Model Dataset\n",
    "Use as benchmark for validity of other models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "densitySLAC = pd.DataFrame()\n",
    "densitySLAC['comp'] = dfSLAC['comp']\n",
    "densitySLAC['density'] = dfSLAC['density (g/cm3)']\n",
    "\n",
    "densitySLAC.dropna(inplace=True)\n",
    "densitySLAC.reset_index(drop=True, inplace=True)\n",
    "densitySLAC = densitySLAC[[(type(x) in (int, float)) for x in densitySLAC['density']]]\n",
    "densitySLAC['density'].astype(float)\n",
    "densitySLAC.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('dropping N/A, non number density values leaves {} values'.format(len(densitySLAC)))\n",
    "densitySLAC.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "densityNREL = pd.DataFrame()\n",
    "densityNREL['comp'] = elastProp_NREL['comp']\n",
    "densityNREL['density'] = elastProp_NREL['density']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "densityNREL.dropna(inplace=True)\n",
    "densityNREL.reset_index(inplace=True)\n",
    "densityNREL = densityNREL[[(type(x) in (int, float)) for x in densityNREL['density']]]\n",
    "densityNREL.reset_index(drop=True, inplace=True)\n",
    "densityNREL['density'].astype(float)\n",
    "densityNREL.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "densityData = densitySLAC.append(densityNREL, ignore_index=True)\n",
    "print('{} = {} + {}?'.format(len(densityData), len(densitySLAC), len(densityNREL)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X_dens = base_featurizer.featurize_many(densityData['comp'], ignore_errors=True)\n",
    "X_dens = np.array(X_dens)\n",
    "X_dens.astype(float)\n",
    "print('Computed {} features'.format(X_dens.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.where(np.isnan(X_dens)))\n",
    "featCleanImpute(X_dens)\n",
    "print(np.where(np.isnan(X_dens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('./datasets/density_features.pkl.gz', 'wb') as fp:\n",
    "    pkl.dump(X_dens, fp)\n",
    "with gzip.open('./datasets/density_data.pkl.gz', 'wb') as fd:\n",
    "    pkl.dump(densityData, fd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model: Density"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build model, Impute unknown values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "density_model = Pipeline([('impute',Imputer()), \n",
    "                          ('model', RandomForestRegressor(n_estimators=100, n_jobs=1, max_features=12))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "density_model.fit(X_dens, densitySLAC['density'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureImp = pd.DataFrame(density_model.steps[1][1].feature_importances_,\n",
    "                          index=dens_featurizer.feature_labels(),\n",
    "                          columns=['importance']).sort_values('importance',ascending=False)\n",
    "featureImp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assess quality of model?\n",
    "what metric to use?  r2 seems fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_sizes, train_scores, valid_scores = learning_curve(density_model, X_dens, densitySLAC['density'], cv=ShuffleSplit())#,\n",
    "                                                          #scoring=r2_scorer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title('Learning Curve, RForest: std model, 12 features')\n",
    "plt.xlabel(\"Training examples: density data\")\n",
    "plt.ylabel(\"default scoring method?\")\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(valid_scores, axis=1)\n",
    "test_scores_std = np.std(valid_scores, axis=1)\n",
    "plt.grid()\n",
    "\n",
    "plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                 color=\"r\")\n",
    "plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                 test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "         label=\"Training score\")\n",
    "plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "         label=\"Cross-validation score\")\n",
    "\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "r2_scorer = make_scorer(r2_score)\n",
    "train_sizes, train_scores, valid_scores = learning_curve(density_model, X_dens, densitySLAC['density'], cv=ShuffleSplit(),\n",
    "                                                          scoring=r2_scorer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title('Learning Curve, RForest: std features, max 12 features')\n",
    "plt.xlabel(\"Training examples: density data\")\n",
    "plt.ylabel(\"$r^2$\")\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(valid_scores, axis=1)\n",
    "test_scores_std = np.std(valid_scores, axis=1)\n",
    "plt.grid()\n",
    "\n",
    "plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                 color=\"r\")\n",
    "plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                 test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "         label=\"Training score\")\n",
    "plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "         label=\"Cross-validation score\")\n",
    "\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot predicted vs actual scatter plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take predicted values from each cross validation set to ensure training not performed on own set.  Take 200 training samples\n",
    "# Probably could have used cross_val_predict\n",
    "kf = KFold(5)\n",
    "rep=0\n",
    "densitySLAC['density_predict'] = np.nan\n",
    "for train_index, test_index in kf.split(densitySLAC['comp']):\n",
    "    print('Split #{}'.format(rep))\n",
    "    density_model.fit(X_dens[train_index,:], densitySLAC['density'][train_index])\n",
    "    \n",
    "    y_densPredict = density_model.predict(X_dens[test_index,:])\n",
    "    densitySLAC['density_predict'][test_index] = y_densPredict\n",
    "    \n",
    "    #print(train_index, test_index)\n",
    "    rep+=1\n",
    "#y_densPredict = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.scatter(densitySLAC['density'], densitySLAC['density_predict'], edgecolors='k')\n",
    "plt.plot([0,30], [0,30], 'r-')\n",
    "plt.xlabel('density [g/cm$^3$]')\n",
    "plt.ylabel('predicted density')\n",
    "\n",
    "plt.xlim([0,25])\n",
    "plt.ylim([0,25])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model: Modulus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elasticSLAC = pd.DataFrame()\n",
    "elasticSLAC['comp'] = dfSLAC['comp']\n",
    "elasticSLAC['E'] = dfSLAC['Young’s  Modulus, E (GPa)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elastic_model = Pipeline([('impute',Imputer()), ('model', RandomForestRegressor(n_estimators=100, n_jobs=1, max_features=12))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
